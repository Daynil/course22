{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Fastai\n",
    "\n",
    "To make sense of the NLP chapter, I'm building out the imdb classifier using all 3 libraries, fastai, hugging faces, and pytorch. It doesn't seem like it makes sense to do a pure python one yet since we did not go over embeddings very much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.text.all as fai_text\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='144441344' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [144441344/144440600 00:56&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Path('/home/daynil/.fastai/data/imdb')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = fai_text.untar_data(fai_text.URLs.IMDB)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = fai_text.get_text_files(path, folders=['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What could have been an excellent hostage movie was totally ruined by what '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = files[0].open().read()\n",
    "txt[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = fai_text.L(o.open().read() for o in files[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and concat the corpus of text, creating a tmp directory with the corpus in a temporary directory (default `./tmp`). \n",
    "\n",
    "Finds the common sequences of characters to create a vocab. E.g., most frequently occuring sequences of chars get their own token.\n",
    "\n",
    "Fastai uses the google tokenizer library [sentencepiece](https://github.com/google/sentencepiece) to do this.\n",
    "\n",
    "After tokenization, the corpus file is deleted and a tokenizer model and vocab file are created in the temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sp_model': Path('tmp/spm.model')}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = fai_text.SubwordTokenizer()\n",
    "sp.setup(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁What ▁could ▁have ▁been ▁an ▁excellent ▁hostage ▁movie ▁was ▁totally ▁ruin'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = sp([txt])\n",
    "\" \".join(next(toks))[:75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastai adds its own functionality on top of google's subword tokenizer. It adds special tokens, like xxbos (beginning of stream indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#234) ['▁xxbos','▁xxmaj','▁what','▁could','▁have','▁been','▁an','▁excellent','▁hostage','▁movie','▁was','▁totally','▁ruined','▁by','▁what','▁apparently','▁looks','▁like','▁a','▁bored','▁director','▁...','▁there','▁were','▁so','▁many','▁direction','s','▁that','▁the','▁movie'...]\n"
     ]
    }
   ],
   "source": [
    "tkn = fai_text.Tokenizer(sp)\n",
    "# Note coll_repr is literally just printing the first x items of a list\n",
    "# But makes it easier to work with lists that are possibly generators, so we'll use that\n",
    "print(fai_text.coll_repr(tkn(txt), 31))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to numericalize our tokens, which just means replacing each token with its index in the vocab.\n",
    "\n",
    "We'll use a small sample of 200 instead of the full corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁xxbos', '▁xxmaj', '▁what', '▁could']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks200 = txts[:200].map(tkn)\n",
    "toks200[0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(#2464) [\\'xxunk\\',\\'xxpad\\',\\'xxbos\\',\\'xxeos\\',\\'xxfld\\',\\'xxrep\\',\\'xxwrep\\',\\'xxup\\',\\'xxmaj\\',\\'▁xxmaj\\',\\'▁the\\',\\'.\\',\\',\\',\\'s\\',\\'▁a\\',\\'▁of\\',\\'▁and\\',\\'▁to\\',\"\\'\",\\'▁it\\'...]'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = fai_text.Numericalize()\n",
    "num.setup(toks200)\n",
    "fai_text.coll_repr(num.vocab, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#234) ['▁xxbos','▁xxmaj','▁what','▁could','▁have','▁been','▁an','▁excellent','▁hostage','▁movie','▁was','▁totally','▁ruined','▁by','▁what','▁apparently','▁looks','▁like','▁a','▁bored'...]\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = tkn(txt)\n",
    "fai_text.coll_repr(toks, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(#234) [TensorText(51),TensorText(9),TensorText(72),TensorText(115),TensorText(44),TensorText(103),TensorText(58),TensorText(700),TensorText(1280),TensorText(28),TensorText(27),TensorText(644),TensorText(0),TensorText(54),TensorText(72),TensorText(1088),TensorText(534),TensorText(55),TensorText(14),TensorText(1881)...]'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = num(toks)\n",
    "fai_text.coll_repr(nums, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁what ▁could ▁have\n"
     ]
    }
   ],
   "source": [
    "print(num.vocab[72], num.vocab[115], num.vocab[44])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to set up a way of feeding a large corpus of text into a language model to train it. \n",
    "\n",
    "With images, we had to resize each image so that it was a consistent size, e.g. 224x224px. This is because tensors require a regular shape in order to function. However, we cannot simply resize text to whatever length we want.\n",
    "\n",
    "Training a language model involves (in this case) asking it to predict the *next word* in some text. Importantly, that means *order matters*. \n",
    "\n",
    "What we can do is concat the entire corpus into a single text stream, then break it out into a number of batches, where each batch starts where the last one ended.\n",
    "\n",
    "Using this text as an example:\n",
    "> In this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the PreProcessor used in the data block API.\\nThen we will study how we build a language model and train it for a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = \"In this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the PreProcessor used in the data block API.\\nThen we will study how we build a language model and train it for a while.\"\n",
    "tokens = tkn(stream)\n",
    "bs, seq_len = 6, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁xxbos</td>\n",
       "      <td>▁xxmaj</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁this</td>\n",
       "      <td>▁chapter</td>\n",
       "      <td>,</td>\n",
       "      <td>▁we</td>\n",
       "      <td>▁will</td>\n",
       "      <td>▁go</td>\n",
       "      <td>▁back</td>\n",
       "      <td>▁over</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁example</td>\n",
       "      <td>▁of</td>\n",
       "      <td>▁class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ifying</td>\n",
       "      <td>▁movie</td>\n",
       "      <td>▁reviews</td>\n",
       "      <td>▁we</td>\n",
       "      <td>▁studi</td>\n",
       "      <td>ed</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁chapter</td>\n",
       "      <td>▁1</td>\n",
       "      <td>▁and</td>\n",
       "      <td>▁dig</td>\n",
       "      <td>▁deep</td>\n",
       "      <td>er</td>\n",
       "      <td>▁under</td>\n",
       "      <td>▁the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>▁surface</td>\n",
       "      <td>.</td>\n",
       "      <td>▁xxmaj</td>\n",
       "      <td>▁first</td>\n",
       "      <td>▁we</td>\n",
       "      <td>▁will</td>\n",
       "      <td>▁look</td>\n",
       "      <td>▁at</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁process</td>\n",
       "      <td>ing</td>\n",
       "      <td>▁steps</td>\n",
       "      <td>▁necessary</td>\n",
       "      <td>▁to</td>\n",
       "      <td>▁convert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁text</td>\n",
       "      <td>▁into</td>\n",
       "      <td>▁numbers</td>\n",
       "      <td>▁and</td>\n",
       "      <td>▁how</td>\n",
       "      <td>▁to</td>\n",
       "      <td>▁custom</td>\n",
       "      <td>ize</td>\n",
       "      <td>▁it</td>\n",
       "      <td>.</td>\n",
       "      <td>▁xxmaj</td>\n",
       "      <td>▁by</td>\n",
       "      <td>▁doing</td>\n",
       "      <td>▁this</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>▁we</td>\n",
       "      <td>'</td>\n",
       "      <td>ll</td>\n",
       "      <td>▁have</td>\n",
       "      <td>▁another</td>\n",
       "      <td>▁example</td>\n",
       "      <td>▁of</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁pre</td>\n",
       "      <td>pro</td>\n",
       "      <td>ce</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>or</td>\n",
       "      <td>▁used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁in</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁da</td>\n",
       "      <td>ta</td>\n",
       "      <td>▁block</td>\n",
       "      <td>▁xxup</td>\n",
       "      <td>▁a</td>\n",
       "      <td>p</td>\n",
       "      <td>i</td>\n",
       "      <td>.</td>\n",
       "      <td>▁xxmaj</td>\n",
       "      <td>▁then</td>\n",
       "      <td>▁we</td>\n",
       "      <td>▁will</td>\n",
       "      <td>▁study</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1         2       3         4         5        6         7   \\\n",
       "0    ▁xxbos  ▁xxmaj       ▁in   ▁this  ▁chapter         ,      ▁we     ▁will   \n",
       "1    ifying  ▁movie  ▁reviews     ▁we    ▁studi        ed      ▁in  ▁chapter   \n",
       "2  ▁surface       .    ▁xxmaj  ▁first       ▁we     ▁will    ▁look       ▁at   \n",
       "3     ▁text   ▁into  ▁numbers    ▁and      ▁how       ▁to  ▁custom       ize   \n",
       "4       ▁we       '        ll   ▁have  ▁another  ▁example      ▁of      ▁the   \n",
       "5       ▁in    ▁the       ▁da      ta    ▁block     ▁xxup       ▁a         p   \n",
       "\n",
       "     8         9       10      11          12      13        14  \n",
       "0   ▁go     ▁back   ▁over    ▁the    ▁example     ▁of    ▁class  \n",
       "1    ▁1      ▁and    ▁dig   ▁deep          er  ▁under      ▁the  \n",
       "2  ▁the  ▁process     ing  ▁steps  ▁necessary     ▁to  ▁convert  \n",
       "3   ▁it         .  ▁xxmaj     ▁by      ▁doing   ▁this         ,  \n",
       "4  ▁pre       pro      ce       s           s      or     ▁used  \n",
       "5     i         .  ▁xxmaj   ▁then         ▁we   ▁will    ▁study  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array([tokens[i*seq_len : (i+1)*seq_len] for i in range(bs)]))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 6 batches of streams **where the order is preserved**, we have the data in the format we need to be able to feed it into a model.\n",
    "\n",
    "However, one further wrinkle is that for a realistic corpus like IMDB reviews, this would be millions of columns wide, not just 15, even if we had a much larger batch size like 64.\n",
    "\n",
    "To solve this, we can create a left-to-right sliding window of mini-streams of data. This still **preserves the order**, but allows us to more tightly control the size of each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch of text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁xxbos</td>\n",
       "      <td>▁xxmaj</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁this</td>\n",
       "      <td>▁chapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ifying</td>\n",
       "      <td>▁movie</td>\n",
       "      <td>▁reviews</td>\n",
       "      <td>▁we</td>\n",
       "      <td>▁studi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>▁surface</td>\n",
       "      <td>.</td>\n",
       "      <td>▁xxmaj</td>\n",
       "      <td>▁first</td>\n",
       "      <td>▁we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁text</td>\n",
       "      <td>▁into</td>\n",
       "      <td>▁numbers</td>\n",
       "      <td>▁and</td>\n",
       "      <td>▁how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>▁we</td>\n",
       "      <td>'</td>\n",
       "      <td>ll</td>\n",
       "      <td>▁have</td>\n",
       "      <td>▁another</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁in</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁da</td>\n",
       "      <td>ta</td>\n",
       "      <td>▁block</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1         2       3         4\n",
       "0    ▁xxbos  ▁xxmaj       ▁in   ▁this  ▁chapter\n",
       "1    ifying  ▁movie  ▁reviews     ▁we    ▁studi\n",
       "2  ▁surface       .    ▁xxmaj  ▁first       ▁we\n",
       "3     ▁text   ▁into  ▁numbers    ▁and      ▁how\n",
       "4       ▁we       '        ll   ▁have  ▁another\n",
       "5       ▁in    ▁the       ▁da      ta    ▁block"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, seq_len = 6, 5\n",
    "df = pd.DataFrame(np.array([tokens[i*15 : i*15+seq_len] for i in range(bs)]))\n",
    "print(\"First batch of text\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second batch of text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>▁we</td>\n",
       "      <td>▁will</td>\n",
       "      <td>▁go</td>\n",
       "      <td>▁back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ed</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁chapter</td>\n",
       "      <td>▁1</td>\n",
       "      <td>▁and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>▁will</td>\n",
       "      <td>▁look</td>\n",
       "      <td>▁at</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁to</td>\n",
       "      <td>▁custom</td>\n",
       "      <td>ize</td>\n",
       "      <td>▁it</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>▁example</td>\n",
       "      <td>▁of</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁pre</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁xxup</td>\n",
       "      <td>▁a</td>\n",
       "      <td>p</td>\n",
       "      <td>i</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1         2     3         4\n",
       "0         ,      ▁we     ▁will   ▁go     ▁back\n",
       "1        ed      ▁in  ▁chapter    ▁1      ▁and\n",
       "2     ▁will    ▁look       ▁at  ▁the  ▁process\n",
       "3       ▁to  ▁custom       ize   ▁it         .\n",
       "4  ▁example      ▁of      ▁the  ▁pre       pro\n",
       "5     ▁xxup       ▁a         p     i         ."
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, seq_len = 6, 5\n",
    "df = pd.DataFrame(np.array([tokens[i*15+seq_len : i*15+2*seq_len] for i in range(bs)]))\n",
    "print(\"Second batch of text\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third batch of text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁over</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁example</td>\n",
       "      <td>▁of</td>\n",
       "      <td>▁class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁dig</td>\n",
       "      <td>▁deep</td>\n",
       "      <td>er</td>\n",
       "      <td>▁under</td>\n",
       "      <td>▁the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ing</td>\n",
       "      <td>▁steps</td>\n",
       "      <td>▁necessary</td>\n",
       "      <td>▁to</td>\n",
       "      <td>▁convert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁xxmaj</td>\n",
       "      <td>▁by</td>\n",
       "      <td>▁doing</td>\n",
       "      <td>▁this</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ce</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>or</td>\n",
       "      <td>▁used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁xxmaj</td>\n",
       "      <td>▁then</td>\n",
       "      <td>▁we</td>\n",
       "      <td>▁will</td>\n",
       "      <td>▁study</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1           2       3         4\n",
       "0   ▁over    ▁the    ▁example     ▁of    ▁class\n",
       "1    ▁dig   ▁deep          er  ▁under      ▁the\n",
       "2     ing  ▁steps  ▁necessary     ▁to  ▁convert\n",
       "3  ▁xxmaj     ▁by      ▁doing   ▁this         ,\n",
       "4      ce       s           s      or     ▁used\n",
       "5  ▁xxmaj   ▁then         ▁we   ▁will    ▁study"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, seq_len = 6, 5\n",
    "df = pd.DataFrame(np.array([tokens[i*15+2*seq_len : i*15+3*seq_len] for i in range(bs)]))\n",
    "print(\"Third batch of text\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this process to the IMDB reviews dataset, we can create a stream by combining the individual documents (each document is a text file with a single review).\n",
    "\n",
    "For more effecient training, we can randomize the order in which the documents are combined into a stream on each epoch. **Importantly, we randomize the order of the documents, not the order of the text within them**.\n",
    "\n",
    "Once we have a stream each epoch, we cut that stream into a batch of fixed-size *consecutive* mini-streams. The model then reads the mini-streams in order.\n",
    "\n",
    "This is done behind the scenes by the fastai `LMDataLoader`. Here, it picks a batch size of 64 automatically, and our stream length is 72."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 72]), torch.Size([64, 72]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums200 = toks200.map(num)\n",
    "dl = fai_text.LMDataLoader(nums200)\n",
    "x,y = fai_text.first(dl)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁xxbos ▁xxmaj ▁what ▁could ▁have ▁been ▁an ▁excellent ▁hostage ▁movie\n",
      "▁xxmaj ▁what ▁could ▁have ▁been ▁an ▁excellent ▁hostage ▁movie ▁was\n"
     ]
    }
   ],
   "source": [
    "# The independent variable is just the start of the text\n",
    "print(' '.join(num.vocab[o] for o in x[0][:10]))\n",
    "# And the label is the same thing, but offset by 1 token\n",
    "# In other words, we want our model to guess the next token, in this case \"_was\"\n",
    "print(' '.join(num.vocab[o] for o in y[0][:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
