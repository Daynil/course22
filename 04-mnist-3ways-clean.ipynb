{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai.data.all as fai_data\n",
    "import fastai.vision.all as fai_vision\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/daynil/.fastai/data/mnist_png')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = fai_data.untar_data(fai_data.URLs.MNIST)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = fai_vision.DataBlock(\n",
    "    blocks=(fai_vision.ImageBlock, fai_vision.CategoryBlock),\n",
    "    get_items=fai_vision.get_image_files,\n",
    "    splitter=fai_vision.GrandparentSplitter('training', 'testing'),\n",
    "    get_y=fai_vision.parent_label\n",
    ").dataloaders(path)\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixels per dimension\n",
    "px_per_dim = 28\n",
    "torch.random.manual_seed(42)\n",
    "\n",
    "def to_torch_tensor(xb: torch.Tensor, yb):\n",
    "    return torch.tensor(xb, device=device), torch.tensor(yb, device=device)\n",
    "\n",
    "def to_bw_flattened(xb):\n",
    "    return (transforms.functional\n",
    "                    .rgb_to_grayscale(xb).squeeze().view(\n",
    "                        xb.shape[0], px_per_dim**2)\n",
    "                )\n",
    "\n",
    "def to_bw_flattened_torch_tensor(batch):\n",
    "    xb, yb = batch\n",
    "    xb = torch.tensor(xb, device=device)\n",
    "    xb = to_bw_flattened(xb)\n",
    "    yb = torch.tensor(yb, device=device)\n",
    "    return xb, yb\n",
    "\n",
    "\n",
    "def accuracy(preds, yb):\n",
    "    accuracy_tns = (preds.argmax(dim=1) == yb).float()\n",
    "    return (accuracy_tns.sum() / len(accuracy_tns)).item()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# This is just to allow me to use to_bw_flattened within a pytorch model\n",
    "# Can ignore, conceptually\n",
    "class GrayFlatLayer(torch.nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super().__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13135/250536970.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xb = torch.tensor(xb, device=device)\n",
      "/tmp/ipykernel_13135/250536970.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yb = torch.tensor(yb, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 19.50469207763672, Avg acc: 0.4068471337579618\n",
      "Avg loss: 11.47065544128418, Avg acc: 0.5615047770700637\n",
      "Avg loss: 8.574058532714844, Avg acc: 0.6432125796178344\n",
      "Avg loss: 7.100707530975342, Avg acc: 0.6889928343949044\n",
      "Avg loss: 6.165310859680176, Avg acc: 0.7165605095541401\n",
      "Avg loss: 5.505612850189209, Avg acc: 0.7348726114649682\n",
      "Avg loss: 5.019713878631592, Avg acc: 0.7505971337579618\n",
      "Avg loss: 4.634152889251709, Avg acc: 0.7621417197452229\n",
      "Avg loss: 4.319098472595215, Avg acc: 0.7710987261146497\n",
      "Avg loss: 4.067386150360107, Avg acc: 0.7814490445859873\n",
      "Avg loss: 3.8423712253570557, Avg acc: 0.7870222929936306\n",
      "Avg loss: 3.6473357677459717, Avg acc: 0.7938893312101911\n",
      "Avg loss: 3.4826388359069824, Avg acc: 0.7984673566878981\n",
      "Avg loss: 3.3330941200256348, Avg acc: 0.8036425159235668\n",
      "Avg loss: 3.203057289123535, Avg acc: 0.8066281847133758\n"
     ]
    }
   ],
   "source": [
    "hidden_neurons = 100\n",
    "mnist_classes = 10\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.001\n",
    "\n",
    "w1 = torch.randn((px_per_dim**2, hidden_neurons), requires_grad=True, device=device)\n",
    "b1 = torch.randn(hidden_neurons, requires_grad=True, device=device)\n",
    "\n",
    "w2 = torch.randn((hidden_neurons, mnist_classes), requires_grad=True, device=device)\n",
    "b2 = torch.randn(mnist_classes, requires_grad=True, device=device)\n",
    "\n",
    "def simple_net(image_batch):\n",
    "    res = image_batch@w1 + b1\n",
    "    res = torch.nn.ReLU()(res)\n",
    "    res = res@w2 + b2\n",
    "    return res\n",
    "\n",
    "def optimize():\n",
    "    params = [w1, b1, w2, b2]\n",
    "    for param in params:\n",
    "        param.data -= param.grad.data * lr\n",
    "        param.grad.zero_()\n",
    "    \n",
    "\n",
    "def train_step(xb, yb):\n",
    "    preds = simple_net(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    acc = accuracy(preds, yb)\n",
    "\n",
    "    loss.backward()\n",
    "    optimize()\n",
    "    return loss, acc\n",
    "\n",
    "def valid_step(xb, yb):\n",
    "    with torch.inference_mode():\n",
    "        preds = simple_net(xb)\n",
    "        loss = loss_fn(preds, yb)\n",
    "        acc = accuracy(preds, yb)\n",
    "        return loss, acc\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in dls.train:\n",
    "        xb, yb = to_bw_flattened_torch_tensor(batch)\n",
    "        loss, acc = train_step(xb, yb)\n",
    "    \n",
    "    tot_loss, tot_acc = 0, 0\n",
    "    for batch in dls.valid:\n",
    "        xb, yb = to_bw_flattened_torch_tensor(batch)\n",
    "        loss, acc = valid_step(xb, yb)\n",
    "        tot_loss += loss\n",
    "        tot_acc += acc\n",
    "\n",
    "    valid_batches = len(dls.valid)\n",
    "    print(f\"Avg loss: {tot_loss / valid_batches}, Avg acc: {tot_acc / valid_batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6710/250536970.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xb = torch.tensor(xb, device=device)\n",
      "/tmp/ipykernel_6710/250536970.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yb = torch.tensor(yb, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 2.1178712844848633, Avg acc: 0.5622014331210191\n",
      "Avg loss: 1.8576154708862305, Avg acc: 0.7061106687898089\n",
      "Avg loss: 1.5482885837554932, Avg acc: 0.7451234076433121\n",
      "Avg loss: 1.2592202425003052, Avg acc: 0.777468152866242\n",
      "Avg loss: 1.0387413501739502, Avg acc: 0.8054339171974523\n",
      "Avg loss: 0.8840926289558411, Avg acc: 0.8267316878980892\n",
      "Avg loss: 0.7757946848869324, Avg acc: 0.8397691082802548\n",
      "Avg loss: 0.69716876745224, Avg acc: 0.8515127388535032\n",
      "Avg loss: 0.6381869316101074, Avg acc: 0.85828025477707\n",
      "Avg loss: 0.5925345420837402, Avg acc: 0.8659434713375797\n",
      "Avg loss: 0.5561208128929138, Avg acc: 0.8709195859872612\n",
      "Avg loss: 0.526505172252655, Avg acc: 0.8750995222929936\n",
      "Avg loss: 0.5020864009857178, Avg acc: 0.8788813694267515\n",
      "Avg loss: 0.481544554233551, Avg acc: 0.8816679936305732\n",
      "Avg loss: 0.46423453092575073, Avg acc: 0.8828622611464968\n"
     ]
    }
   ],
   "source": [
    "hidden_neurons = 100\n",
    "mnist_classes = 10\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.001\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(px_per_dim**2, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, mnist_classes)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "def train_step(xb, yb):\n",
    "    preds = model(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    acc = accuracy(preds, yb)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss, acc\n",
    "\n",
    "def valid_step(xb, yb):\n",
    "    preds = model(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    acc = accuracy(preds, yb)\n",
    "    return loss, acc\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in dls.train:\n",
    "        xb, yb = to_bw_flattened_torch_tensor(batch)\n",
    "        loss, acc = train_step(xb, yb)\n",
    "    \n",
    "    tot_loss, tot_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in dls.valid:\n",
    "            xb, yb = to_bw_flattened_torch_tensor(batch)\n",
    "            loss, acc = valid_step(xb, yb)\n",
    "            tot_loss += loss\n",
    "            tot_acc += acc\n",
    "    \n",
    "    valid_batches = len(dls.valid)\n",
    "    print(f\"Avg loss: {tot_loss / valid_batches}, Avg acc: {tot_acc / valid_batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.133905</td>\n",
       "      <td>2.118620</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.877540</td>\n",
       "      <td>1.858544</td>\n",
       "      <td>0.707300</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.573797</td>\n",
       "      <td>1.549371</td>\n",
       "      <td>0.742100</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.288586</td>\n",
       "      <td>1.260185</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.062684</td>\n",
       "      <td>1.039521</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.919067</td>\n",
       "      <td>0.884853</td>\n",
       "      <td>0.824100</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.796627</td>\n",
       "      <td>0.776330</td>\n",
       "      <td>0.838800</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.697940</td>\n",
       "      <td>0.849700</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.677359</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.619108</td>\n",
       "      <td>0.593043</td>\n",
       "      <td>0.865600</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.566866</td>\n",
       "      <td>0.556536</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.549734</td>\n",
       "      <td>0.527069</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.519820</td>\n",
       "      <td>0.502864</td>\n",
       "      <td>0.877900</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.500683</td>\n",
       "      <td>0.482360</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.474606</td>\n",
       "      <td>0.464923</td>\n",
       "      <td>0.883500</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_neurons = 100\n",
    "mnist_classes = 10\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.001\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    GrayFlatLayer(transforms.Lambda(to_bw_flattened)),\n",
    "    torch.nn.Linear(px_per_dim**2, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, mnist_classes)\n",
    ").to(device)\n",
    "\n",
    "learner = fai_vision.Learner(\n",
    "    dls, model, lr=lr, loss_func=loss_fn, opt_func=fai_vision.SGD, metrics=fai_vision.accuracy\n",
    ")\n",
    "\n",
    "learner.fit(epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.701943</td>\n",
       "      <td>0.463513</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.134884</td>\n",
       "      <td>0.072383</td>\n",
       "      <td>0.977700</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.073699</td>\n",
       "      <td>0.055283</td>\n",
       "      <td>0.982400</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>0.035289</td>\n",
       "      <td>0.989400</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.028342</td>\n",
       "      <td>0.026685</td>\n",
       "      <td>0.991500</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.013671</td>\n",
       "      <td>0.026875</td>\n",
       "      <td>0.992200</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "learner = fai_vision.vision_learner(\n",
    "    dls, fai_vision.resnet18, metrics=accuracy\n",
    ")\n",
    "\n",
    "learner.fine_tune(epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
